#!/usr/bin/env python3
"""
Baseline RAG åŠŸèƒ½æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½ FAISS å’Œ BM25 ç´¢å¼•
2. æµ‹è¯•æ£€ç´¢åŠŸèƒ½
3. è¿è¡Œå‡ ä¸ªç¤ºä¾‹é—®é¢˜
"""

import os
import sys
import json
import pickle
from pathlib import Path
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import yaml
import numpy as np
import faiss
import tiktoken
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def load_config() -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = project_root / "configs" / "experiment_config.yaml"
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def load_indices():
    """åŠ è½½ç´¢å¼•"""
    print("ğŸ“š åŠ è½½ç´¢å¼•...")

    # åŠ è½½ FAISS ç´¢å¼•
    faiss_index_path = project_root / "data" / "indices" / "faiss" / "hotpotqa.index"
    faiss_index = faiss.read_index(str(faiss_index_path))
    print(f"âœ… FAISS ç´¢å¼•åŠ è½½å®Œæˆ: {faiss_index.ntotal} ä¸ªå‘é‡")

    # åŠ è½½æ–‡æ¡£æ˜ å°„
    doc_mapping_path = project_root / "data" / "indices" / "faiss" / "hotpotqa_docs.pkl"
    with open(doc_mapping_path, 'rb') as f:
        chunks = pickle.load(f)
    print(f"âœ… æ–‡æ¡£æ˜ å°„åŠ è½½å®Œæˆ: {len(chunks)} ä¸ªå—")

    # åŠ è½½ BM25 ç´¢å¼•
    bm25_path = project_root / "data" / "indices" / "bm25" / "hotpotqa_bm25.pkl"
    with open(bm25_path, 'rb') as f:
        bm25_index = pickle.load(f)
    print(f"âœ… BM25 ç´¢å¼•åŠ è½½å®Œæˆ")

    return faiss_index, bm25_index, chunks


def retrieve_faiss(query: str, faiss_index, chunks: List[Dict], client, config: Dict, top_k: int = 5):
    """ä½¿ç”¨ FAISS æ£€ç´¢"""
    # å‘é‡åŒ–æŸ¥è¯¢
    response = client.embeddings.create(
        model=config['embedding']['model'],
        input=[query]
    )
    query_vector = np.array([response.data[0].embedding], dtype='float32')

    # å½’ä¸€åŒ–
    if config['faiss']['normalize_vectors']:
        faiss.normalize_L2(query_vector)

    # æ£€ç´¢
    distances, indices = faiss_index.search(query_vector, top_k)

    # è·å–æ–‡æ¡£
    results = []
    for idx, distance in zip(indices[0], distances[0]):
        chunk = chunks[idx]
        results.append({
            "chunk_id": chunk['chunk_id'],
            "title": chunk['title'],
            "text": chunk['text'],
            "score": float(distance)
        })

    return results


def retrieve_bm25(query: str, bm25_index, chunks: List[Dict], top_k: int = 5):
    """ä½¿ç”¨ BM25 æ£€ç´¢"""
    # Tokenize æŸ¥è¯¢
    tokenized_query = query.lower().split()

    # æ£€ç´¢
    scores = bm25_index.get_scores(tokenized_query)

    # è·å– top-k
    top_indices = np.argsort(scores)[::-1][:top_k]

    # è·å–æ–‡æ¡£
    results = []
    for idx in top_indices:
        chunk = chunks[idx]
        results.append({
            "chunk_id": chunk['chunk_id'],
            "title": chunk['title'],
            "text": chunk['text'][:200] + "...",  # åªæ˜¾ç¤ºå‰200å­—ç¬¦
            "score": float(scores[idx])
        })

    return results


def test_retrieval():
    """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ£€ç´¢åŠŸèƒ½")
    print("=" * 60)

    # åŠ è½½é…ç½®å’Œç´¢å¼•
    config = load_config()
    faiss_index, bm25_index, chunks = load_indices()

    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "Who is the president of the United States?",
        "What is the capital of France?",
        "When was the Eiffel Tower built?"
    ]

    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*60}")
        print(f"é—®é¢˜ {i}: {question}")
        print(f"{'='*60}")

        # FAISS æ£€ç´¢
        print("\nğŸ” FAISS æ£€ç´¢ç»“æœ (Top-3):")
        faiss_results = retrieve_faiss(question, faiss_index, chunks, client, config, top_k=3)
        for j, result in enumerate(faiss_results, 1):
            print(f"\n  [{j}] {result['title']} (Score: {result['score']:.4f})")
            print(f"      {result['text'][:150]}...")

        # BM25 æ£€ç´¢
        print("\nğŸ” BM25 æ£€ç´¢ç»“æœ (Top-3):")
        bm25_results = retrieve_bm25(question, bm25_index, chunks, top_k=3)
        for j, result in enumerate(bm25_results, 1):
            print(f"\n  [{j}] {result['title']} (Score: {result['score']:.4f})")
            print(f"      {result['text'][:150]}...")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Baseline RAG åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    test_retrieval()

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ“ å¦‚æœæ£€ç´¢ç»“æœæ­£å¸¸ï¼Œä¸‹ä¸€æ­¥:")
    print("   python scripts/04_build_hipporag.py")


if __name__ == "__main__":
    main()
