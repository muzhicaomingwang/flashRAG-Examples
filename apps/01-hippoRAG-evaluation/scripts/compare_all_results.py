#!/usr/bin/env python3
"""
å¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„æ•ˆæœï¼š
1. Baseline RAG
2. HippoRAGï¼ˆæ ‡å‡†KGï¼‰
3. HippoRAGï¼ˆé«˜è´¨é‡KGï¼‰
"""

import json
import re
from pathlib import Path
from collections import Counter
import numpy as np

def normalize_answer(s):
    """æ ‡å‡†åŒ–ç­”æ¡ˆ"""
    def remove_articles(text):
        return re.sub(r'\b(a|an|the)\b', ' ', text)
    def white_space_fix(text):
        return ' '.join(text.split())
    def remove_punc(text):
        exclude = set('!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
        return ''.join(ch for ch in text if ch not in exclude)
    def lower(text):
        return text.lower()
    return white_space_fix(remove_articles(remove_punc(lower(s))))

def compute_f1(prediction, ground_truth):
    """è®¡ç®—F1åˆ†æ•°"""
    pred_tokens = normalize_answer(prediction).split()
    truth_tokens = normalize_answer(ground_truth).split()

    if len(pred_tokens) == 0 or len(truth_tokens) == 0:
        return int(pred_tokens == truth_tokens)

    common_tokens = Counter(pred_tokens) & Counter(truth_tokens)
    num_same = sum(common_tokens.values())

    if num_same == 0:
        return 0

    precision = num_same / len(pred_tokens)
    recall = num_same / len(truth_tokens)
    f1 = (2 * precision * recall) / (precision + recall)

    return f1

def compute_em(prediction, ground_truth):
    """è®¡ç®—ç²¾ç¡®åŒ¹é…"""
    return int(normalize_answer(prediction) == normalize_answer(ground_truth))

def evaluate_predictions(predictions):
    """è¯„ä¼°é¢„æµ‹ç»“æœ"""
    f1_scores = []
    em_scores = []
    latencies = []

    for pred in predictions:
        if pred['success']:
            f1 = compute_f1(pred['predicted_answer'], pred['gold_answer'])
            em = compute_em(pred['predicted_answer'], pred['gold_answer'])
            f1_scores.append(f1)
            em_scores.append(em)
            latencies.append(pred['latency'])

    return {
        'f1_mean': np.mean(f1_scores) if f1_scores else 0,
        'f1_std': np.std(f1_scores) if f1_scores else 0,
        'em_mean': np.mean(em_scores) if em_scores else 0,
        'em_std': np.std(em_scores) if em_scores else 0,
        'latency_mean': np.mean(latencies) if latencies else 0,
        'latency_median': np.median(latencies) if latencies else 0,
        'success_rate': len(f1_scores) / len(predictions),
        'total': len(predictions)
    }

print('='*80)
print('ä¸‰ç§æ–¹æ³•å®Œæ•´å¯¹æ¯”åˆ†æ')
print('='*80)

# åŠ è½½ç»“æœ
print('\nğŸ“Š åŠ è½½é¢„æµ‹ç»“æœ...')

with open('results/baseline_full/predictions.json', 'r') as f:
    baseline = json.load(f)
print(f'âœ… Baseline RAG: {len(baseline)} ä¸ªé¢„æµ‹')

with open('results/hipporag_full/predictions.json', 'r') as f:
    hipporag_standard = json.load(f)
print(f'âœ… HippoRAG (æ ‡å‡†KG): {len(hipporag_standard)} ä¸ªé¢„æµ‹')

hq_file = 'results/hipporag_high_quality/predictions.json'
if Path(hq_file).exists():
    with open(hq_file, 'r') as f:
        hipporag_hq = json.load(f)
    print(f'âœ… HippoRAG (é«˜è´¨é‡KG): {len(hipporag_hq)} ä¸ªé¢„æµ‹')
    has_hq = True
else:
    print(f'âš ï¸  é«˜è´¨é‡KGç»“æœä¸å­˜åœ¨')
    has_hq = False

# è¯„ä¼°
print('\nğŸ”¬ è®¡ç®—è¯„ä¼°æŒ‡æ ‡...')
baseline_metrics = evaluate_predictions(baseline)
standard_metrics = evaluate_predictions(hipporag_standard)

if has_hq:
    hq_metrics = evaluate_predictions(hipporag_hq)

# ç”ŸæˆæŠ¥å‘Š
report = []
report.append('# ä¸‰ç§æ–¹æ³•å®Œæ•´å¯¹æ¯”åˆ†æ')
report.append('')
report.append('## çŸ¥è¯†å›¾è°±è´¨é‡å¯¹æ¯”')
report.append('')

with open('data/knowledge_graphs/hotpotqa_kg_full_stats.json', 'r') as f:
    standard_stats = json.load(f)

report.append('| KGç‰ˆæœ¬ | æ€»èŠ‚ç‚¹ | æ€»è¾¹ | Entityâ†’Entity | å æ¯” | å›¾å¯†åº¦ |')
report.append('|--------|--------|------|--------------|------|--------|')
report.append(f"| æ ‡å‡†KG | {standard_stats['num_nodes']:,} | {standard_stats['num_edges']:,} | {standard_stats['num_entity_relations']:,} | 1.7% | 0.000008 |")

if has_hq:
    with open('data/knowledge_graphs/hotpotqa_kg_high_quality_stats.json', 'r') as f:
        hq_stats = json.load(f)
    e2e_pct = hq_stats['num_entity_relations'] / hq_stats['num_edges'] * 100
    report.append(f"| é«˜è´¨é‡KG | {hq_stats['num_nodes']:,} | {hq_stats['num_edges']:,} | {hq_stats['num_entity_relations']:,} | {e2e_pct:.1f}% | {hq_stats['graph_density']:.6f} |")

report.append('')

report.append('## æ€§èƒ½å¯¹æ¯”')
report.append('')
report.append('| æ–¹æ³• | F1 Score | Exact Match | å¹³å‡å»¶è¿Ÿ |')
report.append('|------|----------|-------------|----------|')
report.append(f"| Baseline RAG | {baseline_metrics['f1_mean']:.4f} | {baseline_metrics['em_mean']*100:.1f}% | {baseline_metrics['latency_mean']:.2f}s |")
report.append(f"| HippoRAG (æ ‡å‡†KG) | {standard_metrics['f1_mean']:.4f} | {standard_metrics['em_mean']*100:.1f}% | {standard_metrics['latency_mean']:.2f}s |")

if has_hq:
    report.append(f"| HippoRAG (é«˜è´¨é‡KG) | {hq_metrics['f1_mean']:.4f} | {hq_metrics['em_mean']*100:.1f}% | {hq_metrics['latency_mean']:.2f}s |")

report.append('')

report.append('## æå‡å¹…åº¦')
report.append('')
report.append('| å¯¹æ¯” | F1æå‡ | EMæå‡ | å»¶è¿Ÿå˜åŒ– |')
report.append('|------|--------|--------|----------|')

standard_f1_change = (standard_metrics['f1_mean'] - baseline_metrics['f1_mean']) / baseline_metrics['f1_mean'] * 100
standard_em_change = (standard_metrics['em_mean'] - baseline_metrics['em_mean']) / baseline_metrics['em_mean'] * 100
standard_lat_change = (standard_metrics['latency_mean'] - baseline_metrics['latency_mean']) / baseline_metrics['latency_mean'] * 100

report.append(f"| æ ‡å‡†KG vs Baseline | {standard_f1_change:+.1f}% | {standard_em_change:+.1f}% | {standard_lat_change:+.1f}% |")

if has_hq:
    hq_f1_change = (hq_metrics['f1_mean'] - baseline_metrics['f1_mean']) / baseline_metrics['f1_mean'] * 100
    hq_em_change = (hq_metrics['em_mean'] - baseline_metrics['em_mean']) / baseline_metrics['em_mean'] * 100
    hq_lat_change = (hq_metrics['latency_mean'] - baseline_metrics['latency_mean']) / baseline_metrics['latency_mean'] * 100

    report.append(f"| é«˜è´¨é‡KG vs Baseline | {hq_f1_change:+.1f}% | {hq_em_change:+.1f}% | {hq_lat_change:+.1f}% |")
    
    kg_improvement = (hq_metrics['f1_mean'] - standard_metrics['f1_mean']) / standard_metrics['f1_mean'] * 100
    report.append(f"| é«˜è´¨é‡KG vs æ ‡å‡†KG | {kg_improvement:+.1f}% | {(hq_metrics['em_mean'] - standard_metrics['em_mean']) / standard_metrics['em_mean'] * 100:+.1f}% | {(hq_metrics['latency_mean'] - standard_metrics['latency_mean']) / standard_metrics['latency_mean'] * 100:+.1f}% |")

report.append('')

report.append('## ç»“è®º')
report.append('')

if has_hq:
    if hq_f1_change > 5:
        report.append(f'âœ… **é«˜è´¨é‡KGè¯æ˜äº†HippoRAGçš„ä»·å€¼**ï¼ŒF1æå‡{hq_f1_change:.1f}%ï¼Œåœ¨çœŸå®å¤šè·³åœºæ™¯æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚')
    elif hq_f1_change > 0 and hq_f1_change <= 5:
        report.append(f'âš ï¸ **é«˜è´¨é‡KGå¸¦æ¥å°å¹…æå‡**ï¼ŒF1æå‡{hq_f1_change:.1f}%ï¼Œä½†è€ƒè™‘æˆæœ¬å¯èƒ½ä¸å€¼å¾—ã€‚')
        report.append('')
        report.append(f'KGè´¨é‡æ”¹è¿›åï¼ŒEntityâ†’Entityå…³ç³»æå‡{hq_stats["num_entity_relations"]/standard_stats["num_entity_relations"]:.1f}å€ï¼Œä½†F1åªæå‡{hq_f1_change:.1f}%ï¼Œè¯´æ˜ï¼š')
        report.append('- å³ä½¿æœ‰å¯†é›†çš„å®ä½“å…³ç³»ï¼ŒHippoRAGçš„æ”¶ç›Šä»ç„¶æœ‰é™')
        report.append('- ç°ä»£Baseline (å‘é‡æ£€ç´¢ + LLM) å·²ç»è¶³å¤Ÿå¼ºå¤§')
        report.append('- å¯¹é€šç”¨RAGåœºæ™¯ï¼ŒKGçš„å¤æ‚åº¦ä¸å€¼å¾—')
    else:
        report.append(f'âŒ **å³ä½¿ä½¿ç”¨é«˜è´¨é‡KGï¼ŒHippoRAGä»æœªè¶…è¿‡Baseline**ï¼ŒF1å˜åŒ–{hq_f1_change:.1f}%ã€‚')
        report.append('')
        report.append('**è¿™æ˜¯å†³å®šæ€§çš„è¯æ®**ï¼Œè¯æ˜ï¼š')
        report.append('1. KGè´¨é‡ä¸æ˜¯å”¯ä¸€ç“¶é¢ˆ')
        report.append('2. HippoRAGçš„æ ¸å¿ƒå‡è®¾åœ¨é€šç”¨åœºæ™¯ä¸æˆç«‹')
        report.append('3. ç®€å•çš„å‘é‡æ£€ç´¢ + LLMæ¨ç†å·²ç»è¶³å¤Ÿå¥½')
        report.append('4. çŸ¥è¯†å›¾è°±åœ¨RAGä¸­çš„ä»·å€¼è¢«ä¸¥é‡é«˜ä¼°')
        report.append('')
        report.append(f'æŠ•å…¥{hq_stats["total_cost"]:.2f}ç¾å…ƒæ„å»ºé«˜è´¨é‡KGï¼Œä»ç„¶è·å¾—{hq_f1_change:.1f}%çš„è´Ÿæ”¶ç›Šã€‚')

output_file = 'results/three_way_comparison.md'
with open(output_file, 'w') as f:
    f.write('\n'.join(report))

print(f'\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}')
print()
for line in report:
    print(line)
