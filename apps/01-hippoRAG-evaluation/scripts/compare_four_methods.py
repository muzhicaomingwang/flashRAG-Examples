#!/usr/bin/env python3
"""
å››ç§æ–¹æ³•å®Œæ•´å¯¹æ¯”ï¼š
1. BM25ç¨€ç–æ£€ç´¢
2. HippoRAGï¼ˆæ ‡å‡†KGï¼‰
3. HippoRAGï¼ˆé«˜è´¨é‡KGï¼‰
4. FAISSç¨ å¯†æ£€ç´¢
"""

import json
import re
from pathlib import Path
from collections import Counter
import numpy as np

def normalize_answer(s):
    def remove_articles(text):
        return re.sub(r'\b(a|an|the)\b', ' ', text)
    def white_space_fix(text):
        return ' '.join(text.split())
    def remove_punc(text):
        exclude = set('!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
        return ''.join(ch for ch in text if ch not in exclude)
    def lower(text):
        return text.lower()
    return white_space_fix(remove_articles(remove_punc(lower(s))))

def compute_f1(prediction, ground_truth):
    pred_tokens = normalize_answer(prediction).split()
    truth_tokens = normalize_answer(ground_truth).split()
    if len(pred_tokens) == 0 or len(truth_tokens) == 0:
        return int(pred_tokens == truth_tokens)
    common_tokens = Counter(pred_tokens) & Counter(truth_tokens)
    num_same = sum(common_tokens.values())
    if num_same == 0:
        return 0
    precision = num_same / len(pred_tokens)
    recall = num_same / len(truth_tokens)
    f1 = (2 * precision * recall) / (precision + recall)
    return f1

def compute_em(prediction, ground_truth):
    return int(normalize_answer(prediction) == normalize_answer(ground_truth))

def evaluate_predictions(predictions):
    f1_scores = []
    em_scores = []
    latencies = []
    for pred in predictions:
        if pred['success']:
            f1 = compute_f1(pred['predicted_answer'], pred['gold_answer'])
            em = compute_em(pred['predicted_answer'], pred['gold_answer'])
            f1_scores.append(f1)
            em_scores.append(em)
            latencies.append(pred['latency'])
    return {
        'f1_mean': np.mean(f1_scores) if f1_scores else 0,
        'f1_std': np.std(f1_scores) if f1_scores else 0,
        'em_mean': np.mean(em_scores) if em_scores else 0,
        'em_std': np.std(em_scores) if em_scores else 0,
        'latency_mean': np.mean(latencies) if latencies else 0,
        'latency_median': np.median(latencies) if latencies else 0,
        'success_rate': len(f1_scores) / len(predictions),
        'total': len(predictions)
    }

print('='*80)
print('å››ç§æ–¹æ³•å®Œæ•´å¯¹æ¯”åˆ†æ')
print('='*80)

# åŠ è½½ç»“æœ
print('\nğŸ“Š åŠ è½½é¢„æµ‹ç»“æœ...')

methods = {}

# BM25
bm25_file = 'results/bm25/predictions.json'
if Path(bm25_file).exists():
    with open(bm25_file, 'r') as f:
        methods['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰'] = json.load(f)
    print(f'âœ… BM25: {len(methods["BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰"])} ä¸ªé¢„æµ‹')

# Baseline FAISS
with open('results/baseline_full/predictions.json', 'r') as f:
    methods['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰'] = json.load(f)
print(f'âœ… FAISS: {len(methods["FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰"])} ä¸ªé¢„æµ‹')

# HippoRAGæ ‡å‡†
with open('results/hipporag_full/predictions.json', 'r') as f:
    methods['HippoRAGï¼ˆæ ‡å‡†KGï¼‰'] = json.load(f)
print(f'âœ… HippoRAGæ ‡å‡†: {len(methods["HippoRAGï¼ˆæ ‡å‡†KGï¼‰"])} ä¸ªé¢„æµ‹')

# HippoRAGé«˜è´¨é‡
hq_file = 'results/hipporag_high_quality/predictions.json'
if Path(hq_file).exists():
    with open(hq_file, 'r') as f:
        methods['HippoRAGï¼ˆé«˜è´¨é‡KGï¼‰'] = json.load(f)
    print(f'âœ… HippoRAGé«˜è´¨é‡: {len(methods["HippoRAGï¼ˆé«˜è´¨é‡KGï¼‰"])} ä¸ªé¢„æµ‹')

# è¯„ä¼°
print('\nğŸ”¬ è®¡ç®—è¯„ä¼°æŒ‡æ ‡...')
metrics = {}
for name, preds in methods.items():
    metrics[name] = evaluate_predictions(preds)
    print(f'âœ… {name} - F1: {metrics[name]["f1_mean"]:.4f}, EM: {metrics[name]["em_mean"]*100:.1f}%')

# ç”ŸæˆæŠ¥å‘Š
report = []
report.append('# å››ç§æ£€ç´¢æ–¹æ³•å®Œæ•´å¯¹æ¯”åˆ†æ')
report.append('')
report.append('## å®éªŒè®¾è®¡')
report.append('')
report.append('**æ§åˆ¶å˜é‡**ï¼š')
report.append('- LLMï¼šGPT-3.5-turboï¼ˆæ‰€æœ‰æ–¹æ³•ç›¸åŒï¼‰')
report.append('- Temperatureï¼š0.0ï¼ˆæ‰€æœ‰æ–¹æ³•ç›¸åŒï¼‰')
report.append('- Top-Kï¼š5ä¸ªæ–‡æ¡£ç”¨äºç”Ÿæˆï¼ˆæ‰€æœ‰æ–¹æ³•ç›¸åŒï¼‰')
report.append('- æ•°æ®é›†ï¼šHotpotQA 66,573æ–‡æ¡£ï¼Œ500éªŒè¯é—®é¢˜')
report.append('')
report.append('**å˜åŒ–å˜é‡**ï¼šæ£€ç´¢æ–¹æ³•å’ŒçŸ¥è¯†å›¾è°±')
report.append('')

report.append('## æ–¹æ³•è¯´æ˜')
report.append('')
report.append('| æ–¹æ³• | æ£€ç´¢ç±»å‹ | çŸ¥è¯†å›¾è°± | åŸç† |')
report.append('|------|---------|---------|------|')
report.append('| BM25 | ç¨€ç– | æ—  | å…³é”®è¯åŒ¹é…ï¼ˆTF-IDFæ”¹è¿›ç‰ˆï¼‰ |')
report.append('| FAISS | ç¨ å¯† | æ—  | è¯­ä¹‰å‘é‡ç›¸ä¼¼åº¦ |')
report.append('| HippoRAGï¼ˆæ ‡å‡†ï¼‰ | ç¨ å¯† | SpaCyæå– | FAISS + PageRanké‡æ’åº |')
report.append('| HippoRAGï¼ˆé«˜è´¨é‡ï¼‰ | ç¨ å¯† | LLMæå–($4) | FAISS + é«˜è´¨é‡KGé‡æ’åº |')
report.append('')

report.append('## æ€§èƒ½å¯¹æ¯”')
report.append('')
report.append('| æ–¹æ³• | F1 Score | Exact Match | å¹³å‡å»¶è¿Ÿ | æˆåŠŸç‡ |')
report.append('|------|----------|-------------|----------|--------|')

# æŒ‰æ€§èƒ½æ’åº
sorted_methods = sorted(metrics.items(), key=lambda x: x[1]['f1_mean'], reverse=True)
for name, m in sorted_methods:
    line = f"| {name} | {m['f1_mean']:.4f} | {m['em_mean']*100:.1f}% | {m['latency_mean']:.2f}s | {m['success_rate']*100:.1f}% |"
    report.append(line)

report.append('')

# è®¡ç®—ç›¸å¯¹æå‡ï¼ˆä»¥BM25ä¸ºåŸºå‡†ï¼‰
if 'BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰' in metrics:
    bm25_f1 = metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['f1_mean']
    
    report.append('## ç›¸å¯¹BM25çš„æå‡')
    report.append('')
    report.append('| æ–¹æ³• | F1æå‡ | EMæå‡ | å»¶è¿Ÿå˜åŒ– |')
    report.append('|------|--------|--------|----------|')
    
    for name, m in sorted_methods:
        if name != 'BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰':
            f1_change = (m['f1_mean'] - metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['f1_mean']) / metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['f1_mean'] * 100
            em_change = (m['em_mean'] - metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['em_mean']) / metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['em_mean'] * 100
            lat_change = (m['latency_mean'] - metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['latency_mean']) / metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['latency_mean'] * 100
            report.append(f"| {name} | {f1_change:+.1f}% | {em_change:+.1f}% | {lat_change:+.1f}% |")
    
    report.append('')

# è®¡ç®—ç›¸å¯¹æå‡ï¼ˆä»¥FAISSä¸ºåŸºå‡†ï¼‰
faiss_f1 = metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['f1_mean']

report.append('## ç›¸å¯¹FAISSçš„æå‡ï¼ˆKGçš„çœŸå®ä»·å€¼ï¼‰')
report.append('')
report.append('| æ–¹æ³• | F1æå‡ | EMæå‡ | å»¶è¿Ÿå˜åŒ– | ç»“è®º |')
report.append('|------|--------|--------|----------|------|')

for name, m in sorted_methods:
    if 'HippoRAG' in name:
        f1_change = (m['f1_mean'] - faiss_f1) / faiss_f1 * 100
        em_change = (m['em_mean'] - metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['em_mean']) / metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['em_mean'] * 100
        lat_change = (m['latency_mean'] - metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['latency_mean']) / metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['latency_mean'] * 100
        
        if f1_change > 0:
            conclusion = 'KGæœ‰ä»·å€¼'
        elif f1_change > -2:
            conclusion = 'KGåŸºæœ¬æ— ç”¨'
        else:
            conclusion = 'KGæœ‰å®³'
        
        report.append(f"| {name} | {f1_change:+.1f}% | {em_change:+.1f}% | {lat_change:+.1f}% | {conclusion} |")

report.append('')

report.append('## æ ¸å¿ƒç»“è®º')
report.append('')

# åˆ¤æ–­æ’åº
if 'BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰' in metrics:
    ranking = [name for name, _ in sorted_methods]
    
    if ranking[0] == 'FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰':
        report.append('âœ… **FAISSç¨ å¯†æ£€ç´¢æ€§èƒ½æœ€ä½³**')
        report.append('')
        
        if ranking[-1] == 'BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰':
            report.append('**æ€§èƒ½æ’åº**ï¼š')
            report.append('```')
            for i, name in enumerate(ranking, 1):
                f1 = metrics[name]['f1_mean']
                report.append(f'{i}. {name:30} F1 = {f1:.4f}')
            report.append('```')
            report.append('')
            
            # åˆ†æHippoRAGçš„ä½ç½®
            hippo_std_rank = ranking.index('HippoRAGï¼ˆæ ‡å‡†KGï¼‰') + 1
            
            if hippo_std_rank == 2:
                report.append('### HippoRAGä»‹äºBM25å’ŒFAISSä¹‹é—´')
                report.append('')
                report.append('**è¿™è¯´æ˜**ï¼š')
                report.append('- KGæ¯”BM25å¼ºï¼ˆåˆ©ç”¨äº†å‘é‡æ£€ç´¢çš„è¯­ä¹‰ç†è§£ï¼‰')
                report.append('- KGæ¯”FAISSå¼±ï¼ˆå›¾è°±é‡æ’åºåè€Œé™ä½æ€§èƒ½ï¼‰')
                report.append('- **HippoRAGçš„æå‡ä¸»è¦æ¥è‡ªFAISSï¼Œä¸æ˜¯KG**')
            elif hippo_std_rank >= 3:
                report.append('### HippoRAGç”šè‡³å¼±äºBM25ï¼ˆå¦‚æœæ˜¯è¿™æ ·ï¼‰')
                report.append('')
                report.append('**è¿™è¯´æ˜**ï¼š')
                report.append('- KGçš„é‡æ’åºä¸¥é‡ç ´åäº†FAISSçš„æ£€ç´¢è´¨é‡')
                report.append('- çŸ¥è¯†å›¾è°±å®Œå…¨æ— ä»·å€¼')
    
report.append('')
report.append('## å¯¹HippoRAGè®ºæ–‡çš„å½±å“')
report.append('')

if 'BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰' in metrics:
    bm25_f1 = metrics['BM25ï¼ˆç¨€ç–æ£€ç´¢ï¼‰']['f1_mean']
    faiss_f1 = metrics['FAISSï¼ˆç¨ å¯†æ£€ç´¢ï¼‰']['f1_mean']
    hippo_f1 = metrics['HippoRAGï¼ˆæ ‡å‡†KGï¼‰']['f1_mean']
    
    faiss_vs_bm25 = (faiss_f1 - bm25_f1) / bm25_f1 * 100
    hippo_vs_bm25 = (hippo_f1 - bm25_f1) / bm25_f1 * 100
    hippo_vs_faiss = (hippo_f1 - faiss_f1) / faiss_f1 * 100
    
    report.append('**å¦‚æœHippoRAGè®ºæ–‡ç”¨BM25åšBaseline**ï¼š')
    report.append('')
    report.append(f'- è®ºæ–‡å¯èƒ½æŠ¥å‘Šï¼šHippoRAGæ¯”BM25æå‡ {hippo_vs_bm25:.1f}%')
    report.append(f'- å£°ç§°ï¼šKGå¸¦æ¥ {hippo_vs_bm25:.1f}% æå‡')
    report.append('')
    report.append('**çœŸç›¸åˆ†è§£**ï¼š')
    report.append(f'- FAISS vs BM25ï¼š{faiss_vs_bm25:.1f}% ï¼ˆæ£€ç´¢æ–¹æ³•æ”¹è¿›ï¼‰')
    report.append(f'- HippoRAG vs FAISSï¼š{hippo_vs_faiss:.1f}% ï¼ˆKGçš„çœŸå®è´¡çŒ®ï¼‰')
    report.append('')
    report.append('**ç»“è®º**ï¼š')
    if abs(hippo_vs_faiss) < abs(faiss_vs_bm25) / 5:
        report.append(f'- âŒ **KGçš„è´¡çŒ®ï¼ˆ{hippo_vs_faiss:.1f}%ï¼‰è¿œå°äºFAISSï¼ˆ{faiss_vs_bm25:.1f}%ï¼‰**')
        report.append(f'- âŒ **è®ºæ–‡çš„{hippo_vs_bm25:.1f}%æå‡ä¸­ï¼Œ{faiss_vs_bm25/(hippo_vs_bm25)*100:.0f}%æ¥è‡ªFAISSï¼Œä¸æ˜¯KG**')
        report.append('- âŒ **è¿™æ˜¯ä¸¥é‡çš„å­¦æœ¯è¯¯å¯¼**')
    
    report.append('')
    report.append('**æ¬ºéª—æ€§ç­‰çº§**ï¼š')
    deception_score = min(10, int(abs(faiss_vs_bm25) / abs(hippo_vs_faiss)))
    report.append(f'- {"â˜…" * deception_score}/10')
    if deception_score >= 8:
        report.append('- **æ¥è¿‘å­¦æœ¯æ¬ºè¯ˆ**')

report.append('')
report.append('---')
report.append('')
report.append('*å®éªŒæ—¥æœŸï¼š2026-02-04*  ')
report.append('*å®éªŒè€…ï¼šç‹¬ç«‹éªŒè¯*  ')
report.append('*æ–¹æ³•ï¼šä¸¥æ ¼æ§åˆ¶å˜é‡*  ')
report.append('*ç»“è®ºï¼šæ•°æ®é©±åŠ¨*  ')

# ä¿å­˜æŠ¥å‘Š
output_file = 'results/four_way_comparison.md'
with open(output_file, 'w') as f:
    f.write('\n'.join(report))

print(f'\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}')
print()
for line in report:
    print(line)
