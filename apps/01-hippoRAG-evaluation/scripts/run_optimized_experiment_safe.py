#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆå¯¹æ¯”å®éªŒï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰
ä½¿ç”¨å®Œæ•´66Kæ–‡æ¡£ç´¢å¼•å’Œ70%è¦†ç›–çš„KG

æ”¹è¿›:
1. PPRç¼“å­˜é¿å…é‡å¤è®¡ç®—
2. æ–­ç‚¹ç»­ä¼ æœºåˆ¶
3. APIé‡è¯•æœºåˆ¶
4. å†…å­˜ç®¡ç†
5. è¯¦ç»†è¿›åº¦æ˜¾ç¤º
"""

import json
import pickle
import time
import os
import gc
from pathlib import Path
import numpy as np
import faiss
import spacy
import networkx as nx
from openai import OpenAI


class PPRCache:
    """
    Personalized PageRankç¼“å­˜ç±»
    é¿å…å¯¹ç›¸åŒå®ä½“ç»„åˆé‡å¤è®¡ç®—PPR
    """

    def __init__(self, kg, global_pagerank):
        self.kg = kg
        self.global_pr = global_pagerank
        self.cache = {}
        self.hits = 0
        self.misses = 0

    def get_ppr(self, query_entity_ids):
        """è·å–PPRåˆ†æ•°ï¼Œä½¿ç”¨ç¼“å­˜"""
        if not query_entity_ids:
            return self.global_pr

        # ä½¿ç”¨frozensetä½œä¸ºç¼“å­˜keyï¼ˆé¡ºåºæ— å…³ï¼‰
        cache_key = frozenset(query_entity_ids)

        if cache_key in self.cache:
            self.hits += 1
            return self.cache[cache_key]

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œè®¡ç®—PPR
        self.misses += 1
        personalization = {node: 0.0 for node in self.kg.nodes}
        for eid in query_entity_ids:
            personalization[eid] = 1.0 / len(query_entity_ids)

        ppr_scores = nx.pagerank(
            self.kg,
            alpha=0.85,
            personalization=personalization,
            max_iter=100
        )

        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = ppr_scores
        return ppr_scores

    def get_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total = self.hits + self.misses
        hit_rate = self.hits / total if total > 0 else 0
        return {
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': hit_rate,
            'cache_size': len(self.cache)
        }


def load_checkpoint(checkpoint_file):
    """åŠ è½½checkpoint"""
    if Path(checkpoint_file).exists():
        with open(checkpoint_file, 'r') as f:
            return json.load(f)
    return []


def save_checkpoint(results, checkpoint_file):
    """ä¿å­˜checkpoint"""
    Path(checkpoint_file).parent.mkdir(parents=True, exist_ok=True)
    with open(checkpoint_file, 'w') as f:
        json.dump(results, f, indent=2)


def call_openai_with_retry(func, max_retries=3, backoff=2):
    """
    è°ƒç”¨OpenAI API withé‡è¯•æœºåˆ¶
    """
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            wait_time = backoff ** attempt
            print(f'   âš ï¸  API error, retry {attempt+1}/{max_retries} in {wait_time}s: {str(e)[:50]}')
            time.sleep(wait_time)


def print_progress(current, total, start_time, experiment_name=""):
    """æ‰“å°è¿›åº¦ä¿¡æ¯"""
    if current == 0:
        return

    percent = current / total * 100
    elapsed = time.time() - start_time
    rate = elapsed / current
    remaining = rate * (total - current)
    remaining_min = remaining / 60

    print(f'   [{current}/{total}] {percent:.1f}% - '
          f'ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ - '
          f'é¢„è®¡å‰©ä½™: {remaining_min:.1f}åˆ†é’Ÿ - '
          f'å¹³å‡: {rate:.1f}ç§’/é—®é¢˜')


def run_baseline_experiment(validation, faiss_index, chunks, client, checkpoint_file):
    """è¿è¡ŒBaseline RAGå®éªŒ"""
    print('\n' + '='*80)
    print('å®éªŒ 1/2: Baseline RAGï¼ˆ66Kæ–‡æ¡£ï¼‰')
    print('='*80)

    # åŠ è½½checkpoint
    results = load_checkpoint(checkpoint_file)
    start_idx = len(results)

    if start_idx > 0:
        print(f'ğŸ“‹ ä»checkpointæ¢å¤ï¼Œå·²å®Œæˆ: {start_idx}/{len(validation)}')

    start_time = time.time()

    for i in range(start_idx, len(validation)):
        question = validation[i]

        # æ˜¾ç¤ºè¿›åº¦
        if i % 10 == 0 or i == start_idx:
            print_progress(i - start_idx, len(validation) - start_idx, start_time, "Baseline")

        query = question['question']
        gold_answer = question['answer']
        q_start_time = time.time()

        try:
            # å‘é‡åŒ–æŸ¥è¯¢ï¼ˆwithé‡è¯•ï¼‰
            resp = call_openai_with_retry(
                lambda: client.embeddings.create(model='text-embedding-3-small', input=[query])
            )
            q_vec = np.array([resp.data[0].embedding], dtype='float32')
            faiss.normalize_L2(q_vec)

            # FAISSæ£€ç´¢
            distances, indices = faiss_index.search(q_vec, 5)
            retrieved_docs = [chunks[idx] for idx in indices[0]]

            # æ„å»ºcontext
            context = '\n\n'.join([f"Doc {j+1}: {doc['text']}" for j, doc in enumerate(retrieved_docs)])
            prompt = f"""Answer the question based on the context.

Context:
{context}

Question: {query}

Answer (be concise):"""

            # ç”Ÿæˆç­”æ¡ˆï¼ˆwithé‡è¯•ï¼‰
            answer_resp = call_openai_with_retry(
                lambda: client.chat.completions.create(
                    model='gpt-3.5-turbo',
                    messages=[{'role': 'user', 'content': prompt}],
                    temperature=0.0,
                    max_tokens=256
                )
            )

            predicted = answer_resp.choices[0].message.content.strip()

            results.append({
                'question_id': question['id'],
                'question': query,
                'gold_answer': gold_answer,
                'predicted_answer': predicted,
                'latency': time.time() - q_start_time,
                'success': True
            })

        except Exception as e:
            print(f'   âœ— Question {i} failed: {str(e)[:100]}')
            results.append({
                'question_id': question['id'],
                'question': query,
                'gold_answer': gold_answer,
                'predicted_answer': '',
                'latency': time.time() - q_start_time,
                'success': False,
                'error': str(e)
            })

        # æ¯50ä¸ªé—®é¢˜ä¿å­˜checkpoint
        if (i + 1) % 50 == 0:
            save_checkpoint(results, checkpoint_file)
            print(f'   ğŸ’¾ Checkpoint saved at {i+1}/{len(validation)}')

        # æ¯100ä¸ªé—®é¢˜æ¸…ç†å†…å­˜
        if (i + 1) % 100 == 0:
            gc.collect()
            print(f'   ğŸ§¹ Memory cleanup at {i+1}')

    # æœ€ç»ˆä¿å­˜
    save_checkpoint(results, checkpoint_file)

    success = sum(1 for r in results if r['success'])
    print(f'\nâœ… Baselineå®Œæˆ: {success}/{len(results)} ({success/len(results)*100:.1f}%)')

    return results


def run_hipporag_experiment(validation, faiss_index, chunks, kg, pagerank_scores,
                            client, nlp, checkpoint_file):
    """è¿è¡ŒHippoRAGå®éªŒ"""
    print('\n' + '='*80)
    print('å®éªŒ 2/2: HippoRAGï¼ˆ66Kæ–‡æ¡£ï¼Œ70% KGï¼‰')
    print('='*80)

    # åˆå§‹åŒ–PPRç¼“å­˜
    ppr_cache = PPRCache(kg, pagerank_scores)
    print(f'ğŸ”„ PPRç¼“å­˜å·²åˆå§‹åŒ–ï¼ˆå…¨å±€PageRankåŒ…å« {len(pagerank_scores):,} èŠ‚ç‚¹ï¼‰')

    # åŠ è½½checkpoint
    results = load_checkpoint(checkpoint_file)
    start_idx = len(results)

    if start_idx > 0:
        print(f'ğŸ“‹ ä»checkpointæ¢å¤ï¼Œå·²å®Œæˆ: {start_idx}/{len(validation)}')

    start_time = time.time()

    for i in range(start_idx, len(validation)):
        question = validation[i]

        # æ˜¾ç¤ºè¿›åº¦
        if i % 10 == 0 or i == start_idx:
            print_progress(i - start_idx, len(validation) - start_idx, start_time, "HippoRAG")

        query = question['question']
        gold_answer = question['answer']
        q_start_time = time.time()

        try:
            # å‘é‡åŒ–æŸ¥è¯¢ï¼ˆwithé‡è¯•ï¼‰
            resp = call_openai_with_retry(
                lambda: client.embeddings.create(model='text-embedding-3-small', input=[query])
            )
            q_vec = np.array([resp.data[0].embedding], dtype='float32')
            faiss.normalize_L2(q_vec)

            # FAISSæ£€ç´¢ï¼ˆtop 20ï¼‰
            distances, indices = faiss_index.search(q_vec, 20)

            # æå–æŸ¥è¯¢å®ä½“
            query_doc = nlp(query)
            query_entities = [ent.text.lower().strip() for ent in query_doc.ents]
            query_entity_ids = [f"entity_{e.replace(' ', '_')}" for e in query_entities]
            query_entity_ids = [eid for eid in query_entity_ids if kg.has_node(eid)]

            # ä½¿ç”¨PPRç¼“å­˜è·å–åˆ†æ•°
            ppr_scores = ppr_cache.get_ppr(query_entity_ids)

            # é‡æ–°æ’åº
            candidate_chunks = [chunks[idx] for idx in indices[0]]
            reranked = []

            for chunk, distance in zip(candidate_chunks, distances[0]):
                chunk_id = chunk['chunk_id']
                ppr_score = ppr_scores.get(chunk_id, 0.0)
                retrieval_score = 1.0 / (1.0 + float(distance))
                combined_score = 0.5 * ppr_score + 0.5 * retrieval_score
                reranked.append({'chunk': chunk, 'combined_score': combined_score})

            reranked.sort(key=lambda x: x['combined_score'], reverse=True)
            retrieved_docs = [item['chunk'] for item in reranked[:5]]

            # æ„å»ºcontext
            context = '\n\n'.join([f"Doc {j+1}: {doc['text']}" for j, doc in enumerate(retrieved_docs)])
            prompt = f"""Answer the question based on the context.

Context:
{context}

Question: {query}

Answer (be concise):"""

            # ç”Ÿæˆç­”æ¡ˆï¼ˆwithé‡è¯•ï¼‰
            answer_resp = call_openai_with_retry(
                lambda: client.chat.completions.create(
                    model='gpt-3.5-turbo',
                    messages=[{'role': 'user', 'content': prompt}],
                    temperature=0.0,
                    max_tokens=256
                )
            )

            predicted = answer_resp.choices[0].message.content.strip()

            results.append({
                'question_id': question['id'],
                'question': query,
                'gold_answer': gold_answer,
                'predicted_answer': predicted,
                'latency': time.time() - q_start_time,
                'query_entities': query_entities,
                'ppr_cache_hit': len(query_entity_ids) > 0 and ppr_cache.hits > 0,
                'success': True
            })

        except Exception as e:
            print(f'   âœ— Question {i} failed: {str(e)[:100]}')
            results.append({
                'question_id': question['id'],
                'question': query,
                'gold_answer': gold_answer,
                'predicted_answer': '',
                'latency': time.time() - q_start_time,
                'success': False,
                'error': str(e)
            })

        # æ¯50ä¸ªé—®é¢˜ä¿å­˜checkpointå’Œæ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        if (i + 1) % 50 == 0:
            save_checkpoint(results, checkpoint_file)
            stats = ppr_cache.get_stats()
            print(f'   ğŸ’¾ Checkpoint saved at {i+1}/{len(validation)}')
            print(f'   ğŸ“Š PPRç¼“å­˜: å‘½ä¸­ç‡ {stats["hit_rate"]*100:.1f}%, '
                  f'å‘½ä¸­ {stats["hits"]}, æœªå‘½ä¸­ {stats["misses"]}, '
                  f'ç¼“å­˜å¤§å° {stats["cache_size"]}')

        # æ¯100ä¸ªé—®é¢˜æ¸…ç†å†…å­˜
        if (i + 1) % 100 == 0:
            gc.collect()
            print(f'   ğŸ§¹ Memory cleanup at {i+1}')

    # æœ€ç»ˆä¿å­˜
    save_checkpoint(results, checkpoint_file)

    success = sum(1 for r in results if r['success'])
    print(f'\nâœ… HippoRAGå®Œæˆ: {success}/{len(results)} ({success/len(results)*100:.1f}%)')

    # æ˜¾ç¤ºæœ€ç»ˆç¼“å­˜ç»Ÿè®¡
    stats = ppr_cache.get_stats()
    print(f'\nğŸ“Š PPRç¼“å­˜ç»Ÿè®¡:')
    print(f'   å‘½ä¸­ç‡: {stats["hit_rate"]*100:.1f}%')
    print(f'   æ€»å‘½ä¸­: {stats["hits"]}')
    print(f'   æ€»æœªå‘½ä¸­: {stats["misses"]}')
    print(f'   ç¼“å­˜å¤§å°: {stats["cache_size"]}')

    return results


def main():
    """ä¸»å‡½æ•°"""
    print('='*80)
    print('ä¼˜åŒ–ç‰ˆHippoRAGå¯¹æ¯”å®éªŒï¼ˆ66Kæ–‡æ¡£ï¼‰- å®‰å…¨ç‰ˆæœ¬')
    print('='*80)

    # åŠ è½½æ•°æ®
    print('\nğŸ“š åŠ è½½æ•°æ®å’Œç´¢å¼•...')

    validation = []
    with open('data/raw/hotpotqa_validation.jsonl', 'r') as f:
        for line in f:
            validation.append(json.loads(line))
    print(f'âœ… éªŒè¯é›†: {len(validation)} é—®é¢˜')

    # ä½¿ç”¨_fullç‰ˆæœ¬çš„ç´¢å¼•
    faiss_index = faiss.read_index('data/indices/faiss/hotpotqa_full.index')
    with open('data/indices/faiss/hotpotqa_full_docs.pkl', 'rb') as f:
        chunks = pickle.load(f)
    print(f'âœ… FAISS: {faiss_index.ntotal:,} å‘é‡')

    # ä½¿ç”¨_fullç‰ˆæœ¬çš„KG
    with open('data/knowledge_graphs/hotpotqa_kg_full.gpickle', 'rb') as f:
        kg = pickle.load(f)
    with open('data/knowledge_graphs/hotpotqa_pagerank_full.pkl', 'rb') as f:
        pagerank_scores = pickle.load(f)
    print(f'âœ… çŸ¥è¯†å›¾è°±: {kg.number_of_nodes():,} èŠ‚ç‚¹, {kg.number_of_edges():,} è¾¹')

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
    nlp = spacy.load('en_core_web_sm')
    print('âœ… OpenAIå®¢æˆ·ç«¯å’ŒSpaCyå·²åˆå§‹åŒ–')

    # è¿è¡Œå®éªŒ1: Baseline
    baseline_results = run_baseline_experiment(
        validation,
        faiss_index,
        chunks,
        client,
        'results/checkpoint_baseline.json'
    )

    # ä¿å­˜æœ€ç»ˆç»“æœ
    Path('results/baseline_full').mkdir(parents=True, exist_ok=True)
    with open('results/baseline_full/predictions.json', 'w') as f:
        json.dump(baseline_results, indent=2, fp=f)

    # è¿è¡Œå®éªŒ2: HippoRAG
    hipporag_results = run_hipporag_experiment(
        validation,
        faiss_index,
        chunks,
        kg,
        pagerank_scores,
        client,
        nlp,
        'results/checkpoint_hipporag.json'
    )

    # ä¿å­˜æœ€ç»ˆç»“æœ
    Path('results/hipporag_full').mkdir(parents=True, exist_ok=True)
    with open('results/hipporag_full/predictions.json', 'w') as f:
        json.dump(hipporag_results, indent=2, fp=f)

    print('\n' + '='*80)
    print('âœ… ä¼˜åŒ–ç‰ˆå®éªŒå®Œæˆï¼')
    print('='*80)
    print(f'\nç»“æœå·²ä¿å­˜åˆ°:')
    print(f'  - results/baseline_full/predictions.json')
    print(f'  - results/hipporag_full/predictions.json')


if __name__ == '__main__':
    main()
